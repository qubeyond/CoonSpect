services:

  # DBs

  postgres:
    image: postgres:17-alpine
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "${REDIS_PORT}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s

  # Services

  backend:
    build: ./backend/
    restart: always
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      REDIS_HOST: ${REDIS_HOST}
      STT_SERVICE_URL: ${STT_SERVICE_URL}
      LLM_SERVICE_URL: ${LLM_SERVICE_URL}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
    ports:
      - "${BACKEND_PORT}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
  
  frontend:
    build: ./frontend/
    restart: always
    ports:
      - "${FRONTEND_PORT}:80"
    environment:
      VITE_API_URL: ${VITE_API_URL}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
    depends_on:
      - backend

  stt-service:
    build: ./stt-service/
    restart: always
    profiles: ["ml"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: ${GPU_DRIVER}
              count: ${GPU_COUNT}
              capabilities: [${GPU_CAPABILITIES}]
    environment:
      NVIDIA_VISIBLE_DEVICES: ${NVIDIA_VISIBLE_DEVICES}
      LD_LIBRARY_PATH: ${CUDA_LIB_PATH}:$LD_LIBRARY_PATH
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}

  llm-service:
    build: ./llm-service/
    restart: always
    profiles: ["ml"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: ${GPU_DRIVER}
              count: ${GPU_COUNT}
              capabilities: [${GPU_CAPABILITIES}]
    environment:
      NVIDIA_VISIBLE_DEVICES: ${NVIDIA_VISIBLE_DEVICES}
      LD_LIBRARY_PATH: ${CUDA_LIB_PATH}:$LD_LIBRARY_PATH
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
    volumes:
      - ollama_models:/root/.ollama

  # Mocks

  stt-mock:
    build: ./mocks/stt
    ports:
      - "${STT_MOCK_PORT}:8000"

  llm-mock:
    build: ./mocks/llm
    ports:
      - "${LLM_MOCK_PORT}:8000"

  # Other

  volumes:
    postgres_data:
    ollama_models: